<html>
 <H1>
  Training report at: 25-08-2019-12-53-08
 </H1>
 <H2>
  Model name: mlp_one_layer
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   dense_1 (Dense)              (None, 512)               401920
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_2 (Dense)              (None, 10)                5130
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 407,050
  </P>
  <P>
   Trainable params: 407,050
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.96      0.99      0.97       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.97      0.99      0.98      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.93      0.97      0.95      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.96      0.92      0.94      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.96      0.95      0.95       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.94      0.95      0.94       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.96      0.96      0.96       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.96      0.92      0.94      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.96      0.92      0.94       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.91      0.95      0.93      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.95      0.95      0.95     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.95      0.95      0.95     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.95      0.95      0.95     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: mlp_two_layers
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   dense_3 (Dense)              (None, 512)               401920
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_4 (Dense)              (None, 512)               262656
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_5 (Dense)              (None, 10)                5130
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 669,706
  </P>
  <P>
   Trainable params: 669,706
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.98      0.98      0.98       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.98      0.99      0.98      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.96      0.97      0.96      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.96      0.96      0.96      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.96      0.97      0.96       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.96      0.97      0.96       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.97      0.97      0.97       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.99      0.92      0.95      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.97      0.95      0.96       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.92      0.96      0.94      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.96      0.96      0.96     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.96      0.96      0.96     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.96      0.96      0.96     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: mlp_two_layers_dropout
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   dense_6 (Dense)              (None, 512)               401920
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dropout_1 (Dropout)          (None, 512)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_7 (Dense)              (None, 512)               262656
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dropout_2 (Dropout)          (None, 512)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_8 (Dense)              (None, 10)                5130
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 669,706
  </P>
  <P>
   Trainable params: 669,706
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.96      0.98      0.97       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.97      0.99      0.98      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.96      0.95      0.96      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.93      0.96      0.94      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.96      0.95      0.96       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.96      0.93      0.95       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.97      0.96      0.96       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.95      0.96      0.95      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.95      0.94      0.94       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.95      0.93      0.94      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.96      0.96      0.96     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.96      0.96      0.96     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.96      0.96      0.96     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: conv_net
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   conv2d_1 (Conv2D)            (None, 26, 26, 32)        320
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   flatten_1 (Flatten)          (None, 576)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_9 (Dense)              (None, 64)                36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_10 (Dense)             (None, 10)                650
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 93,322
  </P>
  <P>
   Trainable params: 93,322
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.97      0.99      0.98       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.98      1.00      0.99      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.98      0.98      0.98      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.98      0.97      0.98      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.97      0.99      0.98       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.99      0.95      0.97       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.98      0.98      0.98       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.97      0.98      0.97      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.97      0.97      0.97       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.98      0.96      0.97      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: conv_net_dropout
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   conv2d_4 (Conv2D)            (None, 26, 26, 32)        320
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dropout_3 (Dropout)          (None, 13, 13, 32)        0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_6 (Conv2D)            (None, 3, 3, 64)          36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   flatten_2 (Flatten)          (None, 576)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_11 (Dense)             (None, 64)                36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dropout_4 (Dropout)          (None, 64)                0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_12 (Dense)             (None, 10)                650
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 93,322
  </P>
  <P>
   Trainable params: 93,322
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.98      0.98      0.98       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.99      0.98      0.99      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.96      0.97      0.96      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.97      0.98      0.97      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.99      0.95      0.97       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.98      0.97      0.98       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.97      0.99      0.98       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.96      0.96      0.96      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.97      0.95      0.96       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.93      0.96      0.95      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.97      0.97      0.97     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.97      0.97      0.97     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.97      0.97      0.97     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: conv_net_batch_norm
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   conv2d_7 (Conv2D)            (None, 26, 26, 32)        320
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   batch_normalization_1 (Batch (None, 13, 13, 32)        128
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_8 (Conv2D)            (None, 11, 11, 64)        18496
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_9 (Conv2D)            (None, 3, 3, 64)          36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   flatten_3 (Flatten)          (None, 576)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_13 (Dense)             (None, 64)                36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   batch_normalization_2 (Batch (None, 64)                256
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_14 (Dense)             (None, 10)                650
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 93,706
  </P>
  <P>
   Trainable params: 93,514
  </P>
  <P>
   Non-trainable params: 192
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.99      0.99      0.99       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.99      1.00      0.99      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.96      0.99      0.97      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.99      0.99      0.99      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.98      0.98      0.98       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.97      0.99      0.98       892
   </td>
  </tr>
  <tr>
   <td>
    6       1.00      0.96      0.98       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.96      0.99      0.97      1028
   </td>
  </tr>
  <tr>
   <td>
    8       1.00      0.95      0.97       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.98      0.96      0.97      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: conv_net_l1
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   conv2d_10 (Conv2D)           (None, 26, 26, 32)        320
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_7 (MaxPooling2 (None, 13, 13, 32)        0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_11 (Conv2D)           (None, 11, 11, 64)        18496
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_8 (MaxPooling2 (None, 5, 5, 64)          0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_12 (Conv2D)           (None, 3, 3, 64)          36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   flatten_4 (Flatten)          (None, 576)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_15 (Dense)             (None, 64)                36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_16 (Dense)             (None, 10)                650
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 93,322
  </P>
  <P>
   Trainable params: 93,322
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.98      0.99      0.98       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.99      0.97      0.98      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.98      0.95      0.96      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.95      0.98      0.97      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.99      0.96      0.97       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.98      0.97      0.97       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.98      0.97      0.98       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.96      0.97      0.96      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.92      0.97      0.95       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.97      0.95      0.96      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.97      0.97      0.97     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.97      0.97      0.97     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.97      0.97      0.97     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
 <H2>
  Model name: conv_net_l2
 </H2>
 <P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   Layer (type)                 Output Shape              Param #
  </P>
  <P>
   =================================================================
  </P>
  <P>
   conv2d_13 (Conv2D)           (None, 26, 26, 32)        320
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_9 (MaxPooling2 (None, 13, 13, 32)        0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_14 (Conv2D)           (None, 11, 11, 64)        18496
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   max_pooling2d_10 (MaxPooling (None, 5, 5, 64)          0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   conv2d_15 (Conv2D)           (None, 3, 3, 64)          36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   flatten_5 (Flatten)          (None, 576)               0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_17 (Dense)             (None, 64)                36928
  </P>
  <P>
   _________________________________________________________________
  </P>
  <P>
   dense_18 (Dense)             (None, 10)                650
  </P>
  <P>
   =================================================================
  </P>
  <P>
   Total params: 93,322
  </P>
  <P>
   Trainable params: 93,322
  </P>
  <P>
   Non-trainable params: 0
  </P>
  <P>
   _________________________________________________________________
  </P>
  <p>
   <img src="./outputs/model_plot_25-08-2019-12-53-08.png"/>
  </p>
 </P>
 <table>
  <tr>
   <td>
    precision    recall  f1-score   support
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    0       0.95      1.00      0.97       980
   </td>
  </tr>
  <tr>
   <td>
    1       0.98      0.99      0.99      1135
   </td>
  </tr>
  <tr>
   <td>
    2       0.97      0.98      0.98      1032
   </td>
  </tr>
  <tr>
   <td>
    3       0.97      0.98      0.98      1010
   </td>
  </tr>
  <tr>
   <td>
    4       0.97      0.99      0.98       982
   </td>
  </tr>
  <tr>
   <td>
    5       0.99      0.96      0.98       892
   </td>
  </tr>
  <tr>
   <td>
    6       0.99      0.97      0.98       958
   </td>
  </tr>
  <tr>
   <td>
    7       0.98      0.96      0.97      1028
   </td>
  </tr>
  <tr>
   <td>
    8       0.99      0.95      0.97       974
   </td>
  </tr>
  <tr>
   <td>
    9       0.97      0.96      0.97      1009
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    micro avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
    macro avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
    weighted avg       0.98      0.98      0.98     10000
   </td>
  </tr>
  <tr>
   <td>
   </td>
  </tr>
 </table>
</html>